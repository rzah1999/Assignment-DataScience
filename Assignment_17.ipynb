{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
        "Answer :\n",
        "Web scraping is the process of extracting data from websites by using automated software or tools, which can access the website's HTML code, parse it, and extract the desired information. This technique can be used to collect data such as text, images, URLs, and other structured or unstructured data.\n",
        "Web scraping is used for a variety of reasons, such as:\n",
        "Market research: Companies can use web scraping to gather pricing information on products from competitor websites, or to collect customer reviews to improve their own products.\n",
        "\n",
        "Content aggregation: Web scraping can be used to gather news articles or blog posts from various sources and aggregate them on a single platform.\n",
        "\n",
        "Data analysis: Researchers or data scientists can use web scraping to collect data for analysis, such as social media data or information on public opinion.\n",
        "\n",
        "Here are three specific areas where web scraping is commonly used:\n",
        "E-commerce: Web scraping can be used to gather pricing information and product details from e-commerce websites to gain insights into the market and competitor pricing strategies.\n",
        "\n",
        "Social media monitoring: Web scraping can be used to monitor social media platforms for mentions of specific brands or products, which can help businesses to manage their online reputation or respond to customer inquiries.\n",
        "\n",
        "Academic research: Web scraping can be used to gather data for academic research, such as collecting data on public opinion or political sentiment from news websites or social media platforms."
      ],
      "metadata": {
        "id": "3LPKhqE7GhPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What are the different methods used for Web Scraping?\n",
        "Answer :\n",
        "MANUAL SCRAPING\n",
        "COPY-PASTING - In manual scraping, what you do is copy and paste web content. This is time-consuming and repetitive and begs for a more effective means of web scraping. It is however very effective because a website’s defences are targeted at automated scraping and not manual scraping techniques. Even with this benefit, manual scraping is hardly being done because it is time-consuming while automated scraping is quicker and cheaper.\n",
        "AUTOMATED SCRAPING\n",
        "HTML PARSING - There are many web scraping tools and libraries available that can extract data from websites. Some popular examples include BeautifulSoup, Scrapy, and Selenium in Python.\n",
        "\n",
        "DOM PARSING - DOM is short for Document Object Model and it defines the style structure and content of XML files. Scrapers make use of DOM parsers to get an in-depth view of a web page’s structure. They can also use a DOM parser to get nodes containing information and then use a tool like XPath to scrape web pages. Internet Explorer or Firefox browsers can be embedded to extract the entire web page or just parts of it.\n",
        "\n",
        "VERTICAL AGGREGATION - Vertical aggregation platforms are created by companies with access to large scale computing power to target specific verticals. Some companies run the platforms on the cloud. Bots creation and monitoring for specific verticals are done by these platforms without any human intervention. The quality of the bots is measured based on the quality of data they extract since they are created based on the knowledge base for the specific vertical.\n",
        "\n",
        "XPATH - XML Path Language is a query language that is used with XML documents. XPath can be used to navigate XML documents because of their tree-like structure by selecting nodes based on different parameters. XPath can be used together with DOM parsing to scrape an entire web page.\n",
        "\n",
        "GOOGLE SHEETS - Google sheets are a web scraping tool that is quite popular among web scrapers. From within sheets, a scraper can make use of IMPORT XML (,) function to scrape as much data as is needed from websites. This method is only useful when specific data or patterns are required from a website. You can also use this command to check if your website is secure from scraping.\n",
        "\n",
        "TEXT PATTERN MATCHING - This is a matching technique that involves the use of the UNIX grep command and is used with popular programming languages like Perl or Python."
      ],
      "metadata": {
        "id": "qg3hDwF4Gjye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Beautiful Soup? Why is it used?\n",
        "Answer :\n",
        "Beautiful Soup is a Python library used for web scraping purposes. It is a popular parsing library that is used to extract data from HTML and XML documents. Beautiful Soup can parse the HTML code of a web page and extract the relevant data, such as links, images, and text, by providing a simple and intuitive interface.\n",
        "Beautiful Soup is used for web scraping because:\n",
        "It is easy to learn and use: Beautiful Soup is a beginner-friendly library that is easy to install and use. Its intuitive and flexible interface makes it easy to navigate the HTML code and extract the desired data.\n",
        "\n",
        "It can handle imperfect HTML code: Many web pages have imperfect HTML code, which can cause errors when parsing. Beautiful Soup can handle such imperfect HTML code and still extract the relevant data.\n",
        "\n",
        "It supports multiple parsing methods: Beautiful Soup supports multiple parsing methods, including HTML and XML parsing, which makes it versatile and useful for a wide range of web scraping tasks.\n",
        "\n",
        "It has a large community: Beautiful Soup has a large community of developers who contribute to its development and provide support. This makes it a reliable and stable library for web scraping.\n",
        "\n",
        "In summary, Beautiful Soup is a powerful and versatile web scraping library that can extract data from HTML and XML documents. Its ease of use, support for imperfect HTML code, and support for multiple parsing methods make it a popular choice among web scrapers.\n",
        "Example of Beautiful Soup to get top 5 result of search query Product in flipkart website here i have considered smart watch for men"
      ],
      "metadata": {
        "id": "4maPSL0UGyCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "# Setup\n",
        "ua = UserAgent()\n",
        "search_query = \"smart watch for men\".replace(\" \", \"+\")\n",
        "amazon_url = f\"https://www.amazon.com/s?k={search_query}\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": ua.random,\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
        "}\n",
        "\n",
        "response = requests.get(amazon_url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = bs(response.text, \"html.parser\")\n",
        "    products = soup.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})\n",
        "    print(f\"Found {len(products)} products.\")\n",
        "\n",
        "    names = []\n",
        "    top5_urls = []\n",
        "\n",
        "    for i, product in enumerate(products[:10]):  # Scan first 10 to increase chances\n",
        "        try:\n",
        "            # Title may be in different span depending on layout\n",
        "            title_element = product.find(\"h2\")\n",
        "            if title_element and title_element.find(\"span\"):\n",
        "                title_text = title_element.find(\"span\").get_text(strip=True)\n",
        "                names.append(title_text)\n",
        "\n",
        "                # Get product URL from the 'a' tag\n",
        "                link_tag = title_element.find(\"a\", href=True)\n",
        "                if link_tag:\n",
        "                    # Ensure the link is a complete URL\n",
        "                    full_link = link_tag['href']\n",
        "                    if full_link.startswith('/'):\n",
        "                        full_link = \"https://www.amazon.com\" + full_link\n",
        "                    top5_urls.append(full_link)\n",
        "                else:\n",
        "                    top5_urls.append(\"N/A\")  # In case URL not found\n",
        "\n",
        "            # Stop after 5 valid results\n",
        "            if len(names) == 5:\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping product {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Check if we got any results\n",
        "    if names and top5_urls:\n",
        "        df = pd.DataFrame({'Product_Title': names, 'URL': top5_urls})\n",
        "        print(df)\n",
        "    else:\n",
        "        print(\"No valid product titles or links found.\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve Amazon page. Status code: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qaZZoCqTGAR",
        "outputId": "0474c89b-d203-43c4-d930-5546ed4bd03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16 products.\n",
            "                                       Product_Title  URL\n",
            "0  Smart Watch for Men Women, Alexa Built-in Fitn...  N/A\n",
            "1  Smart Watch, 1.85\" Smartwatch for Men Women (A...  N/A\n",
            "2  Smart Watch(Answer/Make Call), 1.91\" Smartwatc...  N/A\n",
            "3  Smart Watch with Alexa Built-in‌, 1.83'' Touch...  N/A\n",
            "4  Smart Watch for Men Women, 1.96\" Fitness Track...  N/A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from urllib.request import urlopen, Request\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "# Initialize UserAgent for rotating user-agents\n",
        "ua = UserAgent()\n",
        "\n",
        "# URL to scrape (search query for 'smart watch for men' on Amazon)\n",
        "search_query = \"smart watch for men\"\n",
        "search_query = search_query.replace(\" \", \"+\")\n",
        "amazon_url = \"https://www.amazon.com/s?k=\" + search_query\n",
        "\n",
        "# Function to make request with rotating user agent and error handling\n",
        "def make_request(url):\n",
        "    headers = {\n",
        "        'User-Agent': ua.random,  # Using random user-agent\n",
        "        'Accept-Language': 'en-US,en;q=0.9',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7'\n",
        "    }\n",
        "\n",
        "    req = Request(url, headers=headers)\n",
        "\n",
        "    # Introduce a random delay (between 20 and 40 seconds)\n",
        "    delay = random.uniform(20, 40)\n",
        "    print(f\"Waiting for {delay:.2f} seconds...\")  # Print delay time\n",
        "    time.sleep(delay)\n",
        "\n",
        "    try:\n",
        "        response = urlopen(req)\n",
        "        return response.read()\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Fetch the page content using the function\n",
        "amazon_page = make_request(amazon_url)\n",
        "\n",
        "if amazon_page:\n",
        "    amazon_html = bs(amazon_page, 'html.parser')\n",
        "\n",
        "    # Getting all product names and URLs\n",
        "    products = amazon_html.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})\n",
        "\n",
        "    names = []\n",
        "    top5_urls = []\n",
        "\n",
        "    for i, product in enumerate(products[:5]):  # Iterate through the top 5 products\n",
        "        # Updated title selector (replace with the actual selector)\n",
        "        title_element = product.find(\"h2\", {\"class\": \"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"})\n",
        "        if title_element:\n",
        "            title_element = title_element.find(\"a\") # find the <a> tag within the h2\n",
        "            # If title_element is found, extract the text\n",
        "            if title_element:\n",
        "                product_name = title_element.text.strip()\n",
        "                names.append(product_name)\n",
        "\n",
        "            # Find the URL element within the same product container\n",
        "            url_element = product.find(\"a\", {\"class\": \"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"})\n",
        "            if url_element:\n",
        "                product_url = \"https://www.amazon.com\" + url_element['href']\n",
        "                top5_urls.append(product_url)\n",
        "                print(f\"Result {i+1}: {product_name}\")\n",
        "            else:\n",
        "                print(f\"URL not found for product {i+1}: {product_name}\")\n",
        "                top5_urls.append(None) # Append None if URL is not found to maintain list length\n",
        "        else:\n",
        "            print(f\"Title not found for product {i+1}\")\n",
        "\n",
        "    # Create a DataFrame with Product Titles and URLs\n",
        "    df = pd.DataFrame({'Product_Title': names, \"URL\": top5_urls})\n",
        "    display(df)  # Using display for better formatting in Jupyter\n",
        "else:\n",
        "    print(\"Failed to retrieve the page. Please try again later.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "NrZziQJnYpNd",
        "outputId": "19a5c4a3-0e5c-42d1-abe0-ece3715a138e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for 21.99 seconds...\n",
            "Title not found for product 1\n",
            "Title not found for product 2\n",
            "Title not found for product 3\n",
            "Title not found for product 4\n",
            "Title not found for product 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Product_Title, URL]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bf904d7-de7d-46c8-9c28-b7c2e6c60b6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product_Title</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bf904d7-de7d-46c8-9c28-b7c2e6c60b6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bf904d7-de7d-46c8-9c28-b7c2e6c60b6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bf904d7-de7d-46c8-9c28-b7c2e6c60b6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_4a60e52b-909a-4c89-9252-c63825502f68\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4a60e52b-909a-4c89-9252-c63825502f68 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 0,\n  \"fields\": [\n    {\n      \"column\": \"Product_Title\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from urllib.request import urlopen, Request\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "# Initialize UserAgent for rotating user-agents\n",
        "ua = UserAgent()\n",
        "\n",
        "# URL to scrape (search query for 'smart watch for men' on Amazon)\n",
        "search_query = \"smart watch for men\"\n",
        "search_query = search_query.replace(\" \", \"+\")\n",
        "amazon_url = \"https://www.amazon.com/s?k=\" + search_query\n",
        "\n",
        "# Function to make request with rotating user agent and error handling\n",
        "def make_request(url):\n",
        "    headers = {\n",
        "        'User-Agent': ua.random,  # Using random user-agent\n",
        "        'Accept-Language': 'en-US,en;q=0.9',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7'\n",
        "    }\n",
        "\n",
        "    req = Request(url, headers=headers)\n",
        "\n",
        "    # Introduce a random delay (between 20 and 40 seconds)\n",
        "    delay = random.uniform(20, 40)\n",
        "    print(f\"Waiting for {delay:.2f} seconds...\")  # Print delay time\n",
        "    time.sleep(delay)\n",
        "\n",
        "    try:\n",
        "        response = urlopen(req)\n",
        "        return response.read()\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Fetch the page content using the function\n",
        "amazon_page = make_request(amazon_url)\n",
        "\n",
        "if amazon_page:\n",
        "    amazon_html = bs(amazon_page, 'html.parser')\n",
        "\n",
        "    # Getting all product names and URLs\n",
        "    products = amazon_html.find_all(\"div\", {\"data-component-type\": \"s-search-result\"})\n",
        "\n",
        "    names = []\n",
        "    top5_urls = []\n",
        "\n",
        "    for i, product in enumerate(products[:5]):  # Iterate through the top 5 products\n",
        "        # --- DEBUGGING ---\n",
        "        print(f\"\\n--- DEBUG: Product {i + 1} ---\")\n",
        "        #print(product.prettify())  # Print the HTML of the product for inspection (optional)\n",
        "        # --- END DEBUGGING ---\n",
        "\n",
        "        # Updated title selector\n",
        "        title_element = product.find(\"span\", {\"class\": \"a-size-base-plus a-color-base a-text-normal\"})\n",
        "\n",
        "        # Updated URL selector\n",
        "        url_element = product.find(\"a\", {\"class\": \"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"})\n",
        "\n",
        "        if title_element and url_element:\n",
        "            names.append(title_element.text.strip())  # Extract text and strip whitespace\n",
        "            top5_urls.append(\"https://www.amazon.com\" + url_element['href'])\n",
        "            print(f\"Result {i+1}: {title_element.text.strip()}\")\n",
        "        else:\n",
        "            print(f\"Title or URL not found for product {i+1}\")\n",
        "\n",
        "    # Create a DataFrame with Product Titles and URLs\n",
        "    df = pd.DataFrame({'Product_Title': names, \"URL\": top5_urls})\n",
        "    display(df)  # Using display for better formatting in Jupyter\n",
        "else:\n",
        "    print(\"Failed to retrieve the page. Please try again later.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "XPIQJrSPbbKl",
        "outputId": "9f8e9c58-72ba-4e6a-9397-423a12cf8549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for 23.93 seconds...\n",
            "\n",
            "--- DEBUG: Product 1 ---\n",
            "Title or URL not found for product 1\n",
            "\n",
            "--- DEBUG: Product 2 ---\n",
            "Title or URL not found for product 2\n",
            "\n",
            "--- DEBUG: Product 3 ---\n",
            "Title or URL not found for product 3\n",
            "\n",
            "--- DEBUG: Product 4 ---\n",
            "Title or URL not found for product 4\n",
            "\n",
            "--- DEBUG: Product 5 ---\n",
            "Title or URL not found for product 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Product_Title, URL]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41833272-a72f-480b-8cc7-a8caea7840c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product_Title</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41833272-a72f-480b-8cc7-a8caea7840c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41833272-a72f-480b-8cc7-a8caea7840c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41833272-a72f-480b-8cc7-a8caea7840c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_fae7f908-2cc9-4e6e-944c-1629e0f0e312\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fae7f908-2cc9-4e6e-944c-1629e0f0e312 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 0,\n  \"fields\": [\n    {\n      \"column\": \"Product_Title\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Why is flask used in this Web Scraping project?\n",
        "Answer:\n",
        "Flask is a web framework that is commonly used to build web applications and APIs in Python. While it is not required for web scraping, it can be useful in certain scenarios.\n",
        "In the context of a web scraping project, Flask is used to create a simple web interface that allows users to input URLs or search queries and view the scraped data in a user-friendly format. For example, you could create a Flask app that takes a search query for a product on Flipkart, scrapes the results page, and displays the relevant information (such as product names, prices, and ratings) in a table on the app's homepage.\n",
        "Using Flask in this way can make it easier to share the results of your web scraping project with others, as they can access the scraped data through a web interface rather than needing to run the scraping code themselves.\n",
        "\n"
      ],
      "metadata": {
        "id": "hqYA3suj2a-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Write the names of AWS services used in this project. Also, explain the use of each service.\n",
        "Answer :\n",
        "Two AWS Services used in this project are:\n",
        "Elastic Beanstalk\n",
        "Code Pipeline\n",
        "1. Elastic Beanstalk\n",
        "Elastic Beanstalk is a fully managed service provided by Amazon Web Services (AWS) that allows developers to easily deploy, manage, and scale web applications and services written in popular programming languages like Java, Python, Node.js, PHP, Ruby, Go, and .NET. With Elastic Beanstalk, developers can focus on writing code without worrying about the underlying infrastructure, as the service handles provisioning and configuration of the resources needed to run the application.\n",
        "\n",
        "Here are some key features of Elastic Beanstalk:\n",
        "\n",
        "Platform as a Service (PaaS): Elastic Beanstalk abstracts away the underlying infrastructure and provides a simple interface for developers to deploy their applications. Developers simply upload their application code, and Elastic Beanstalk handles the rest, including provisioning the necessary resources (such as compute instances, load balancers, and databases) and configuring the environment.\n",
        "\n",
        "Multi-language Support: Elastic Beanstalk supports a wide range of programming languages, frameworks, and platforms, including Java, Python, Node.js, PHP, Ruby, Go, and .NET. It also supports popular web servers like Apache, Nginx, and IIS.\n",
        "\n",
        "Easy Deployment: Developers can deploy their applications to Elastic Beanstalk using a variety of methods, including the Elastic Beanstalk console, the AWS CLI, or APIs. Elastic Beanstalk supports versioning of deployments, so developers can roll back to a previous version if needed.\n",
        "\n",
        "Auto Scaling: Elastic Beanstalk automatically scales the application up or down based on demand, ensuring that the application is always available and responsive to users. It can also automatically balance traffic across multiple instances of the application to optimize performance.\n",
        "\n",
        "Monitoring and Logging: Elastic Beanstalk provides monitoring and logging capabilities that allow developers to monitor the health and performance of their application, and troubleshoot issues if they arise. It also integrates with other AWS services like CloudWatch and Elastic Load Balancing to provide a complete solution for monitoring and managing applications.\n",
        "\n",
        "Overall, Elastic Beanstalk is a powerful and flexible service that can help developers quickly and easily deploy and manage web applications and services on AWS.\n",
        "\n",
        "2. Code Pipeline\n",
        "AWS CodePipeline is a fully managed continuous delivery service provided by Amazon Web Services (AWS). It automates the release process for applications, enabling developers to rapidly and reliably build, test, and deploy their code changes.\n",
        "\n",
        "Here are some key features of AWS CodePipeline:\n",
        "\n",
        "Pipeline Creation: Developers can create custom pipelines for their applications, specifying the source code repository, build tools, testing frameworks, deployment targets, and other settings. They can also define the stages of the pipeline and the actions that should be performed in each stage.\n",
        "\n",
        "Source Code Integration: CodePipeline integrates with a wide range of source code repositories, including AWS CodeCommit, GitHub, and Bitbucket. Developers can configure their pipelines to automatically detect code changes in the repository and trigger the build and deployment process.\n",
        "\n",
        "Build and Test Automation: CodePipeline supports a variety of build and test tools, including AWS CodeBuild, Jenkins, and Bamboo. Developers can configure their pipelines to run automated tests as part of the build process, ensuring that code changes meet quality standards before being deployed.\n",
        "\n",
        "Deployment Automation: CodePipeline can deploy applications to a wide range of targets, including Amazon EC2 instances, AWS Elastic Beanstalk environments, and AWS Lambda functions. It can also integrate with other AWS services like AWS CodeDeploy and AWS CloudFormation to support more complex deployment scenarios.\n",
        "\n",
        "Continuous Monitoring: CodePipeline provides continuous monitoring of the pipeline and its stages, giving developers visibility into the progress of each stage and the status of each action. It also integrates with AWS CloudWatch to provide monitoring and alerting capabilities for the pipeline and the application.\n",
        "\n",
        "Overall, AWS CodePipeline is a powerful tool for automating the release process for applications, enabling developers to deploy changes quickly and reliably while maintaining high quality standards. By eliminating the need for manual intervention and automating many of the tedious and error-prone tasks involved in software deployment, CodePipeline can help teams deliver software faster and with fewer errors."
      ],
      "metadata": {
        "id": "0XyNuR6o2h0_"
      }
    }
  ]
}